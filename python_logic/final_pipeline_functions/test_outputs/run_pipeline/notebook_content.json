{
    "cells": [
        {
            "source": "# Introduction\n\nThis notebook demonstrates the process of loading, processing, and analyzing weather data.\nIt covers data loading, data processing, and statistical calculations using the provided scripts.",
            "outputs": [],
            "metadata": {},
            "cell_type": "markdown",
            "execution_count": null
        },
        {
            "source": "# Environment Setup\nimport csv\nimport pandas as pd\n\nimport os\n\n# Set up file paths\ndata_dir = 'data'\nraw_data_dir = os.path.join(data_dir, 'raw')\nprocessed_data_dir = os.path.join(data_dir, 'processed')\nos.makedirs(processed_data_dir, exist_ok=True)",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Data Loading\n\n### Reading Data Files\n\nLoad raw weather data using the `read_csv` function.",
            "outputs": [],
            "metadata": {},
            "cell_type": "markdown",
            "execution_count": null
        },
        {
            "source": "# Define the read_csv function from weather_reading.py\ndef read_csv(file_path):\n    with open(file_path, 'r') as f:\n        reader = csv.reader(f)\n        data = []\n        for row in reader:\n            data.append(row)\n    return data",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Load data from CSV files\ndata_2018 = read_csv(os.path.join(raw_data_dir, 'weather_2018.csv'))\ndata_2019 = read_csv(os.path.join(raw_data_dir, 'weather_2019.csv'))\ndata_2020 = read_csv(os.path.join(raw_data_dir, 'weather_2020.csv'))",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Display first few rows of data\nprint('Data 2018:', data_2018[:5])\nprint('Data 2019:', data_2019[:5])\nprint('Data 2020:', data_2020[:5])",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Data Processing\n\n### Processing Weather Data\n\nProcess the weather data to calculate and print the average temperature and humidity.",
            "outputs": [],
            "metadata": {},
            "cell_type": "markdown",
            "execution_count": null
        },
        {
            "source": "# Define the process_weather function from weather_processing.py\ndef process_weather(file_path):\n    with open(file_path, 'r') as f:\n        reader = csv.reader(f)\n        next(reader)  # Skip header\n        total_temp = 0\n        total_humidity = 0\n        count = 0\n        for row in reader:\n            total_temp += int(row[1])\n            total_humidity += int(row[2])\n            count += 1\n        avg_temp = total_temp / count\n        avg_humidity = total_humidity / count\n    print(f'Average Temperature: {avg_temp}')\n    print(f'Average Humidity: {avg_humidity}')",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Process data for 2018 and 2019\nprint('Processing 2018 Data:')\nprocess_weather(os.path.join(raw_data_dir, 'weather_2018.csv'))\n\nprint('\\nProcessing 2019 Data:')\nprocess_weather(os.path.join(raw_data_dir, 'weather_2019.csv'))",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Data Conversion Utility\n\n### Data Cleaning with Utilities\n\nUtilize the `to_float` function to handle potential non-numeric data.",
            "outputs": [],
            "metadata": {},
            "cell_type": "markdown",
            "execution_count": null
        },
        {
            "source": "# Define the to_float function from utils.py\ndef to_float(value):\n    try:\n        return float(value)\n    except:\n        return 'N/A'",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Apply to_float to data\ndef read_and_clean_csv(file_path):\n    with open(file_path, 'r') as f:\n        reader = csv.reader(f)\n        data = []\n        for row in reader:\n            cleaned_row = [to_float(value) for value in row]\n            data.append(cleaned_row)\n    return data\n\nclean_data_2018 = read_and_clean_csv(os.path.join(raw_data_dir, 'weather_2018.csv'))\nprint('Cleaned Data 2018:', clean_data_2018[:5])",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Statistical Analysis\n\n### Calculating Min and Max Temperatures\n\nUse `get_min_max` to find the minimum and maximum temperatures.",
            "outputs": [],
            "metadata": {},
            "cell_type": "markdown",
            "execution_count": null
        },
        {
            "source": "# Define the get_min_max function from stats_calculator.py\ndef get_min_max(data):\n    min_temp = float('inf')\n    max_temp = float('-inf')\n    for row in data:\n        if len(row) > 1 and row[1] != 'N/A':\n            temp = row[1]\n            if temp < min_temp:\n                min_temp = temp\n            if temp > max_temp:\n                max_temp = temp\n    return min_temp, max_temp",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Calculate min and max temperatures from cleaned data\nmin_temp, max_temp = get_min_max(clean_data_2018)\nprint(f'Minimum Temperature: {min_temp}')\nprint(f'Maximum Temperature: {max_temp}')",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Saving Processed Data\n\n### Persisting Results\n\nSave the calculated statistics to a CSV file.",
            "outputs": [],
            "metadata": {},
            "cell_type": "markdown",
            "execution_count": null
        },
        {
            "source": "# Save results to a CSV file\nimport csv\n\noutput_file = os.path.join(processed_data_dir, 'weather_stats_2018.csv')\nwith open(output_file, 'w', newline='') as f:\n    writer = csv.writer(f)\n    writer.writerow(['Year', 'Min Temp', 'Max Temp', 'Avg Temp', 'Avg Humidity'])\n    writer.writerow([\n        '2018',\n        min_temp,\n        max_temp,\n        'N/A',  # Placeholder for average temperature\n        'N/A'   # Placeholder for average humidity\n    ])\n\nprint(f'Results saved to {output_file}')",
            "outputs": [],
            "metadata": {},
            "cell_type": "code",
            "execution_count": null
        },
        {
            "source": "# Future Directions\n\n- Incorporate error handling for missing or corrupt data.\n- Utilize advanced statistical methods or visualizations.\n- Implement comprehensive logging mechanisms.",
            "outputs": [],
            "metadata": {},
            "cell_type": "markdown",
            "execution_count": null
        },
        {
            "source": "# Conclusion\n\nThis notebook demonstrated loading, processing, and analyzing weather data.\nFurther improvements can be made to enhance the robustness of the data analysis pipeline.",
            "outputs": [],
            "metadata": {},
            "cell_type": "markdown",
            "execution_count": null
        }
    ],
    "metadata": {
        "kernel_info": {
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8",
            "codemirror_mode": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}