{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a8cf1e7d",
            "metadata": {},
            "source": [
                "# Data Analysis and Modeling Notebook\n",
                "\n",
                "This notebook provides a comprehensive walkthrough of loading, processing, training, and visualizing data using the project's codebase."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "96ab1dfa",
            "metadata": {},
            "source": [
                "## Dependencies and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "63c36653",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Set up inline plotting\n",
                "%matplotlib inline\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ea70c542",
            "metadata": {},
            "source": [
                "## Data Handling"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aa850003",
            "metadata": {},
            "source": [
                "### Loading Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "30a0714e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(filepath):\n",
                "    data = pd.read_csv(filepath)\n",
                "    return data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "b287a482",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specify the file path for the data\n",
                "data_filepath = 'data/raw_data.csv'  # Adjust this path as necessary\n",
                "\n",
                "# Load the data\n",
                "data = load_data(data_filepath)\n",
                "\n",
                "# Display the first few rows of the data\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9130597a",
            "metadata": {},
            "source": [
                "## Data Cleaning"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c928b360",
            "metadata": {},
            "source": [
                "### Cleaning Process"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "6c2ae748",
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_data(data):\n",
                "    data = data.dropna()\n",
                "    data = data[data['value'] >= 0]\n",
                "    return data\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "2a8519b7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean the data\n",
                "cleaned_data = clean_data(data)\n",
                "\n",
                "# Display a summary of the cleaned data\n",
                "cleaned_data.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a9b8dd3c",
            "metadata": {},
            "source": [
                "## Data Saving"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ddb9e387",
            "metadata": {},
            "source": [
                "### Save Clean Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "dde06107",
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_clean_data(data, filepath):\n",
                "    data.to_csv(filepath, index=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "ed0e03ac",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Specify the file path to save the cleaned data\n",
                "cleaned_data_filepath = 'data/cleaned_data.csv'  # Adjust this path as necessary\n",
                "\n",
                "# Save the cleaned data\n",
                "save_clean_data(cleaned_data, cleaned_data_filepath)\n",
                "\n",
                "# Verify that data is saved correctly by loading again\n",
                "cleaned_data = load_data(cleaned_data_filepath)\n",
                "\n",
                "cleaned_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2d43a65c",
            "metadata": {},
            "source": [
                "## Data Exploration and Visualization"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39ee9a05",
            "metadata": {},
            "source": [
                "### Plot Initial Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "b86cdf50",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_data(data):\n",
                "    plt.figure(figsize=(10,6))\n",
                "    plt.plot(data['date'], data['value'])\n",
                "    plt.xlabel('Date')\n",
                "    plt.ylabel('Value')\n",
                "    plt.title('Value over Time')\n",
                "    plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "a3dbe5eb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the cleaned data\n",
                "plot_data(cleaned_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6c120405",
            "metadata": {},
            "source": [
                "## Model Training"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e6695541",
            "metadata": {},
            "source": [
                "### Train the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "6a2eb7de",
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(X, y):\n",
                "    model = LinearRegression()\n",
                "    model.fit(X, y)\n",
                "    return model\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "dcfcf83a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert 'date' to datetime if not already\n",
                "cleaned_data['date'] = pd.to_datetime(cleaned_data['date'])\n",
                "\n",
                "# Create features\n",
                "cleaned_data['date_ordinal'] = cleaned_data['date'].map(pd.Timestamp.toordinal)\n",
                "\n",
                "# Define features and target\n",
                "X = cleaned_data[['date_ordinal']]\n",
                "y = cleaned_data['value']\n",
                "\n",
                "# Split data into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Train the model\n",
                "model = train_model(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "64e4419a",
            "metadata": {},
            "source": [
                "## Model Evaluation"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "036916c2",
            "metadata": {},
            "source": [
                "### Generate Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "a042c1e3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict(model, X_new):\n",
                "    predictions = model.predict(X_new)\n",
                "    return predictions\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "43e6ef2a",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions on the test set\n",
                "y_pred = predict(model, X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d3ae1344",
            "metadata": {},
            "source": [
                "### Evaluate Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "fc569bd9",
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model, X_test, y_test):\n",
                "    score = model.score(X_test, y_test)\n",
                "    return score\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "c17a1398",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluate the model performance\n",
                "score = evaluate_model(model, X_test, y_test)\n",
                "print(f'Model R² Score: {score:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "23b0a1b4",
            "metadata": {},
            "source": [
                "## Result Visualization"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2699eebc",
            "metadata": {},
            "source": [
                "### Visualize Model Outcomes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "8e0ef9a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare data for plotting\n",
                "X_test_sorted = X_test.sort_index()\n",
                "y_test_sorted = y_test.loc[X_test_sorted.index]\n",
                "y_pred_sorted = y_pred[np.argsort(X_test.index)]\n",
                "\n",
                "# Convert date ordinal back to datetime\n",
                "dates = X_test_sorted['date_ordinal'].map(pd.Timestamp.fromordinal)\n",
                "\n",
                "# Plot Actual vs Predicted values over time\n",
                "plt.figure(figsize=(10,6))\n",
                "plt.plot(dates, y_test_sorted, color='blue', label='Actual')\n",
                "plt.plot(dates, y_pred_sorted, color='red', linestyle='--', label='Predicted')\n",
                "plt.xlabel('Date')\n",
                "plt.ylabel('Value')\n",
                "plt.title('Actual vs Predicted Values Over Time')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ea05358f",
            "metadata": {},
            "source": [
                "## Summarizing Functionality (Optional)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6f20dc4d",
            "metadata": {},
            "source": [
                "### Generate Summaries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "ebd2e866",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import openai\n",
                "\n",
                "def summarize_functions(python_file_string):\n",
                "    openai.api_key = 'YOUR_API_KEY'  # Replace with your actual API key\n",
                "    \n",
                "    response = openai.ChatCompletion.create(\n",
                "        model=\"gpt-4\",\n",
                "        messages=[\n",
                "            {\n",
                "                \"role\": \"system\",\n",
                "                \"content\": \"You are a python code summarizer. You will see python code. You should summarize all functions based on what they do with respect to the whole script.\"\n",
                "            },\n",
                "            {\n",
                "                \"role\": \"user\",\n",
                "                \"content\": python_file_string\n",
                "            }\n",
                "        ],\n",
                "        temperature=0,\n",
                "        max_tokens=500,\n",
                "    )\n",
                "    \n",
                "    summary = response['choices'][0]['message']['content']\n",
                "    return summary\n",
                "\n",
                "def summarize_functions_in_directory(directory_path, output_json_path):\n",
                "    function_summaries = {}\n",
                "\n",
                "    # Walk through all files and subdirectories within the directory\n",
                "    for root, _, files in os.walk(directory_path):\n",
                "        for filename in files:\n",
                "            if filename.endswith('.py'):\n",
                "                # Get the full file path\n",
                "                file_path = os.path.join(root, filename)\n",
                "                \n",
                "                # Compute the relative path from the root directory\n",
                "                relative_path = os.path.relpath(file_path, directory_path)\n",
                "                \n",
                "                with open(file_path, 'r') as file:\n",
                "                    python_file_string = file.read()\n",
                "                \n",
                "                # Get the function summaries using the summarize_functions function\n",
                "                try:\n",
                "                    summary = summarize_functions(python_file_string)\n",
                "                except Exception as e:\n",
                "                    print(f\"Error summarizing {relative_path}: {e}\")\n",
                "                    summary = {\"error\": str(e)}\n",
                "                \n",
                "                # Add the summary to the dictionary with the relative path as the key\n",
                "                function_summaries[relative_path] = summary\n",
                "\n",
                "    # Write the collected summaries to the output JSON file\n",
                "    with open(output_json_path, 'w') as json_file:\n",
                "        json.dump(function_summaries, json_file, indent=4)\n",
                "\n",
                "    print(f\"Function summaries have been written to {output_json_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "e95d40e3",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example usage\n",
                "\n",
                "# Set the directory path containing Python scripts\n",
                "directory_path = 'scripts'  # Adjust this path as necessary\n",
                "\n",
                "# Specify the output JSON file path\n",
                "output_json_path = 'function_descriptions.json'\n",
                "\n",
                "# Summarize functions in the directory\n",
                "# Note: Ensure you have replaced 'YOUR_API_KEY' with your actual OpenAI API key before running.\n",
                "# This code requires an active internet connection and valid API credentials.\n",
                "\n",
                "summarize_functions_in_directory(directory_path, output_json_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f0989459",
            "metadata": {},
            "source": [
                "## Conclusion and Further Directions\n",
                "\n",
                "In this notebook, we have loaded, cleaned, and explored the data, trained a Linear Regression model, evaluated its performance, and visualized the results.\n",
                "\n",
                "Further improvements could include exploring more complex models, feature engineering, and hyperparameter tuning to improve model performance."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "74677921",
            "metadata": {},
            "source": [
                "**Note:** Ensure that all file paths are correctly specified according to your project's directory structure. Replace `'YOUR_API_KEY'` with your actual OpenAI API key when using the summarization functionality."
            ]
        }
    ],
    "metadata": {
        "kernel_info": {
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": "python",
            "name": "python",
            "version": "3.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
